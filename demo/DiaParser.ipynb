{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DiaParser\n",
    "**Direct Attentive Dependency Parser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1021 12:54:27.761593 140104082409280 file_utils.py:39] PyTorch version 1.5.0 available.\n",
      "I1021 12:54:29.640621 140104082409280 file_utils.py:55] TensorFlow version 2.4.0-dev20200826 available.\n"
     ]
    }
   ],
   "source": [
    "from diaparser.parsers import Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a parser\n",
    "Load a pretrained model for English, named `en_ewt.electra-base`, i.e. a parser trained on the English EWT treebank, using the transformner model `electra-base-disciminator`.\n",
    "\n",
    "The model will be downloaded anc cached locally for further use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-21 15:26:27 INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/config.json from cache at /home/attardi/.cache/torch/transformers/9236d197566a7f1be2b2151f5afcc5a8e17f31e1e23c52f3cdf2340019986e78.88ba6e8e7d5a7936e86d6f2551fe19c236dc57c24da163907cd0544e9933f6ee\n",
      "2020-10-21 15:26:27 INFO: Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_attentions\": true,\n",
      "  \"output_hidden_states\": true,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-21 15:26:28 INFO: loading weights file https://cdn.huggingface.co/google/electra-base-discriminator/pytorch_model.bin from cache at /home/attardi/.cache/torch/transformers/1e208ba81f889d92ba15c70c4c400416d5ac7a2d017a6be053d69a5c41b9c6af.b7514d01ce5acfe02313470cce3175018852a5e8cbcb8784268ab87dc21daf4c\n",
      "2020-10-21 15:26:30 INFO: Weights from pretrained model not used in ElectraModel: ['electra.embeddings_project.weight', 'electra.embeddings_project.bias']\n",
      "2020-10-21 15:26:32 INFO: loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/config.json from cache at /home/attardi/.cache/torch/transformers/9236d197566a7f1be2b2151f5afcc5a8e17f31e1e23c52f3cdf2340019986e78.88ba6e8e7d5a7936e86d6f2551fe19c236dc57c24da163907cd0544e9933f6ee\n",
      "2020-10-21 15:26:32 INFO: Model config ElectraConfig {\n",
      "  \"architectures\": [\n",
      "    \"ElectraForPreTraining\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"embedding_size\": 768,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"electra\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "2020-10-21 15:26:33 INFO: loading file https://s3.amazonaws.com/models.huggingface.co/bert/google/electra-base-discriminator/vocab.txt from cache at /home/attardi/.cache/torch/transformers/ff085885d4c95651587af553adadd34a26de8a663f2cef709635b48b3bed2bbd.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "2020-10-21 15:26:33 ERROR: Using bos_token, but it is not set yet.\n",
      "2020-10-21 15:26:33 ERROR: Using eos_token, but it is not set yet.\n"
     ]
    }
   ],
   "source": [
    "parser = Parser.load('en_ewt.electra-base')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may parse plain text, by telling the language used: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parser.predict('She enjoys playing tennis.', text='en')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dataset` is an instance of `diaparser.utils.Dataset` containing the predicted syntactic trees.\n",
    "\n",
    "Let's look at the first one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1\tShe\t_\t_\t_\t_\t2\tnsubj\t_\t_\n",
       "2\tenjoys\t_\t_\t_\t_\t0\troot\t_\t_\n",
       "3\tplaying\t_\t_\t_\t_\t2\txcomp\t_\t_\n",
       "4\ttennis\t_\t_\t_\t_\t3\tobj\t_\t_\n",
       "5\t.\t_\t_\t_\t_\t2\tpunct\t_\t_"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.sentences[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or you can provide tokenized text, as weel ask to see the estimated probabiity for each predicted arc:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = parser.predict('She', 'enjoys', 'playing', 'tennis', '.']], prob=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may then look at individual fields of the tokens in a sentence and the probability of their arcs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "arcs:  [2, 0, 2, 3, 2]\n",
      "rels:  ['nsubj', 'root', 'xcomp', 'obj', 'punct']\n",
      "probs: tensor([1.0000, 1.0000, 1.0000, 1.0000, 0.9999])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(f\"arcs:  {dataset.arcs[0]}\\n\"\n",
    "      f\"rels:  {dataset.rels[0]}\\n\"\n",
    "      f\"probs: {dataset.probs[0].gather(1,torch.tensor(dataset.arcs[0]).unsqueeze(1)).squeeze(-1)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
